{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning and Decision Making"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratory 1: Markov chains\n",
    "\n",
    "In the end of the lab, you should export the notebook to a Python script (File >> Download as >> Python (.py)). Your file should be named `padi-lab1-groupXX.py`, where the `XX` corresponds to your group number and should be submitted to the e-mail <adi.tecnico@gmail.com>. \n",
    "\n",
    "Make sure...\n",
    "\n",
    "* **... that the subject is of the form `[<group n.>] LAB <lab n.>`.** \n",
    "\n",
    "* **... to strictly respect the specifications in each activity, in terms of the intended inputs, outputs and naming conventions.** \n",
    "\n",
    "In particular, after completing the activities you should be able to replicate the examples provided (although this, in itself, is no guarantee that the activities are correctly completed).\n",
    "\n",
    "### 1. The Markov chain model\n",
    "\n",
    "Consider once again the shuttle modeling problem described in the Homework and for which you wrote a Markov chain model:\n",
    "\n",
    "<img src=\"shuttle.png\" width=\"800px\">\n",
    "\n",
    "Recall that your chain should describe the motion of the single shuttle traveling the network, where: \n",
    "\n",
    "* All stops are considered similar, in terms of shuttle behavior;\n",
    "* At each moment, there is a single shuttle traversing the city;\n",
    "* When at I.S.T. TagusPark, the shuttle will go directly to Sete Rios with a probability of 70%, and to Oeiras with a 30% probability. Similarly, when at Sete Rios, the shuttle will go directly to I.S.T. Alameda with a 50% probability, and through Praça de Londres with a 50% probability.\n",
    "\n",
    "In this first activity, you will implement your Markov chain model in Python. You should label the different shuttle stops as `'0'`, `'1'`, `'2'`, `'3'`, `'4'` (note that these are strings), from left to right in the diagram above. For example, \"I.S.T. TagusPark\" corresponds to `'0'`, while \"Praça de Londres\" corresponds to `'3'`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Activity 1.        \n",
    "\n",
    "Write a function named `load_chain` that receives **no input arguments** and returns, as output, a two-element tuple corresponding to the Markov chain, where:\n",
    "\n",
    "* ... the first element is a tuple containing an enumeration of the state-space (i.e., each element of the tuple corresponds to a state of the chain, represented as a string).\n",
    "* ... the second element is a `numpy` array corresponding to the transition probability matrix for the chain.\n",
    "\n",
    "**Note**: Don't forget to import `numpy`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T17:37:30.996024Z",
     "start_time": "2020-09-24T17:37:30.987841Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add your code here.\n",
    "def load_chain():\n",
    "    stateSpace = (\"0\",\"1\",\"2\",\"3\",\"4\")\n",
    "    transition = np.array([[0,0.3,0.7,0,0], [0,0,1,0,0], [0,0,0,0.5,0.5], [0,0,0,0,1], [1,0,0,0,0]])\n",
    "    return (stateSpace, transition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide below an example of application of the function, that you can use as a first \"sanity check\" for your code. Note, however, that the fact that you can replicate the examples below is not indicative that your code is correct.\n",
    "\n",
    "```python\n",
    "print('Number of states:', len(M[0]))\n",
    "print('Type of states:', type(M[0][0]))\n",
    "print('\\nTransition probability matrix (type):', type(M[1]))\n",
    "print('Transition probability matrix (dimension):', M[1].shape)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Number of states: 5\n",
    "Type of states: <class 'str'>\n",
    "\n",
    "Transition probability matrix (type): <class 'numpy.ndarray'>\n",
    "Transition probability matrix (dimension): (5, 5)\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next activity, you will use the Markov chain model to evaluate the likelihood of any given path for the bot.\n",
    "\n",
    "---\n",
    "\n",
    "#### Activity 2.\n",
    "\n",
    "Write a function `prob_trajectory` that receives, as inputs, \n",
    "\n",
    "* ... a Markov chain in the form of a tuple like the one returned by the function in Activity 1;\n",
    "* ... a trajectory, corresponding to a sequence of states (i.e., a tuple or list of strings, each string corresponding to a state).\n",
    "\n",
    "Your function should return, as output, a floating point number corresponding to the probability of observing the provided trajectory, taking the first state in the trajectory as initial state. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T17:40:07.912333Z",
     "start_time": "2020-09-24T17:40:07.904515Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add your code here.\n",
    "def prob_trajectory(chain, trajectory):\n",
    "    res = 1;\n",
    "    previousStep = int(trajectory[0])\n",
    "    for iStep in range(1, len(trajectory)):\n",
    "        step = int(trajectory[iStep])\n",
    "        res *= chain[1][previousStep][step]\n",
    "        previousStep = step\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of application of the function with the chain $M$ from Activity 1.\n",
    "\n",
    "```python\n",
    "print('Prob. of trajectory (1, 2, 3):', prob_trajectory(M, ('1', '2', '3')))\n",
    "print('Prob. of trajectory (4, 0, 1, 2, 3):', prob_trajectory(M, ('4', '0', '1', '2', '3')))\n",
    "print('Prob. of trajectory (4, 0, 4):', prob_trajectory(M, ('4', '0', '4')))\n",
    "print('Prob. of trajectory (0, 2, 4):', prob_trajectory(M, ('0', '2', '4')))\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Prob. of trajectory (1, 2, 3): 0.5\n",
    "Prob. of trajectory (4, 0, 1, 2, 3): 0.15\n",
    "Prob. of trajectory (4, 0, 4): 0.0\n",
    "Prob. of trajectory (0, 2, 4): 0.35\n",
    "```\n",
    "\n",
    "Note that your function should work with **any** Markov chain that is specified as a tuple like the one from Activity 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next activities explore the notion of *stationary distribution* for the chain, a central concept in the the PageRank algorithm.\n",
    "\n",
    "---\n",
    "\n",
    "#### Activity 3\n",
    "\n",
    "Write a function `stationary_dist` that receives, as input, a Markov chain in the form of a tuple like the one returned by the function in Activity 1. Your function should return, as output, a `numpy` array corresponding to a row vector containing the stationary distribution for the chain.\n",
    "\n",
    "**Note:** The stationary distribution is a *left* eigenvector of the transition probability matrix associated to the eigenvalue 1. As such, you may find useful the numpy function `numpy.linalg.eig`. Also, recall that the stationary distribution is *a distribution*.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T17:41:48.907805Z",
     "start_time": "2020-09-24T17:41:48.892401Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add your code here.\n",
    "def stationary_dist(chain):\n",
    "    values, vectors= np.linalg.eig(np.transpose(chain[1])) # Get left eigen values\n",
    "    #valuesCloseOne = [np.abs(v -1) for v in values] # Calculate distance from eigen values to 1\n",
    "    valuesCloseOne = []\n",
    "    for v in values:\n",
    "        valuesCloseOne.append(np.abs(v -1))\n",
    "    dist = vectors[:,np.argmin(valuesCloseOne)].real # Get not normalized distribution from the value that is closer to 1\n",
    "    return dist.T/np.sum(dist.T) #Normalizing Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of application of the function with the chain $M$ from Activity 1.\n",
    "\n",
    "```python\n",
    "u_star = stationary_dist(M)\n",
    "\n",
    "print('Stationary distribution:')\n",
    "print(u_star)\n",
    "\n",
    "u_prime = u_star.dot(M[1])\n",
    "\n",
    "print('\\nIs u* * P = u*?', np.all(np.isclose(u_prime, u_star)))\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Stationary distribution:\n",
    "[0.263 0.079 0.263 0.132 0.263]\n",
    "\n",
    "Is u* * P = u*? True\n",
    "```\n",
    "\n",
    "All numbers above have been rounded to 3 decimal cases. You **should not** round your results, but can use the numbers above as a comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complement Activity 3, you will now empirically establish that the chain is ergodic, i.e., no matter where the bot starts, its visitation frequency will eventually converge to the stationary distribution.\n",
    "\n",
    "---\n",
    "\n",
    "#### Activity 4.\n",
    "\n",
    "Write a function `compute_dist` that receives, as inputs, \n",
    "\n",
    "* ... a Markov chain in the form of a tuple like the one returned by the function in Activity 1;\n",
    "* ... a row vector (a numpy array) corresponding to the initial distribution for the chain;\n",
    "* ... an integer $N$, corresponding to the number of steps that the bot is expected to take.\n",
    "\n",
    "Your function should return, as output, a row vector (a `numpy` array) containing the distribution after $N$ steps of the chain.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T17:42:29.107319Z",
     "start_time": "2020-09-24T17:42:29.099857Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add your code here.\n",
    "def compute_dist(chain, initDist, nStep):\n",
    "    return initDist.dot(np.linalg.matrix_power(chain[1],nStep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of application of the function with the chain $M$ from Activity 1.\n",
    "\n",
    "```python\n",
    "# Number of states\n",
    "nS = len(M[0])\n",
    "\n",
    "# Initial, uniform distribution\n",
    "u = np.ones((1, nS)) / nS\n",
    "\n",
    "# Distrbution after 100 steps\n",
    "v = compute_dist(M, u, 10)\n",
    "print('\\nIs u * P^10 = u*?', np.all(np.isclose(v, u_star)))\n",
    "\n",
    "# Distrbution after 1000 steps\n",
    "v = compute_dist(M, u, 100)\n",
    "print('\\nIs u * P^100 = u*?', np.all(np.isclose(v, u_star)))\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "Is u * P^10 = u*? False\n",
    "\n",
    "Is u * P^100 = u*? True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the chain ergodic? Justify, based on the results above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">_Add your answer here:_</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity 4: We can conclude this chain is ergodic since for a high value of t (time step) it converges to the stationary distribution calculated with compute_dist.\n"
     ]
    }
   ],
   "source": [
    "print(\"Activity 4: We can conclude this chain is ergodic since for a high value of t (time step) it converges to the stationary distribution calculated with stationary_dist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Simulation\n",
    "\n",
    "In this part of the lab, you will *simulate* the actual bot, and empirically compute the visitation frequency of each state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Activity 5\n",
    "\n",
    "Write down a function `simulate` that receives, as inputs, \n",
    "\n",
    "* ... a Markov chain in the form of a tuple like the one returned by the function in Activity 1;\n",
    "* ... a row vector (a `numpy` array) corresponding to the initial distribution for the chain;\n",
    "* ... an integer $N$, corresponding to the number of steps that the bot is expected to take.\n",
    "\n",
    "Your function should return, as output, a tuple containing a trajectory of $N$ steps obtained from the initial distribution provided. Each element in the tuple should be a string corresponding to a state index.\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** You may find useful to import the numpy module `numpy.random`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T17:43:39.189231Z",
     "start_time": "2020-09-24T17:43:38.832378Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add your code here.\n",
    "def simulate(chain, rowInitDist, nSteps):\n",
    "    trajectory =  []\n",
    "    dist = rowInitDist[0];\n",
    "    for i in range(nSteps):\n",
    "        trajectory += rnd.choice(list(chain[0]),p=dist)\n",
    "        dist = chain[1][int(trajectory[-1])]\n",
    "    return tuple(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of application of the function with the chain $M$ from Activity 1.\n",
    "\n",
    "```python\n",
    "# Number of states\n",
    "nS = len(M[0])\n",
    "\n",
    "# Initial, uniform distribution\n",
    "u = np.ones((1, nS)) / nS\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate short trajectory\n",
    "traj = simulate(M, u, 10)\n",
    "print(traj)\n",
    "\n",
    "# Simulate a long trajectory\n",
    "traj = simulate(M, u, 10000)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```\n",
    "('1', '2', '4', '0', '1', '2', '3', '4', '0', '2')\n",
    "```\n",
    "\n",
    "Note that, even if the seed is fixed, it is possible that your trajectories are slightly different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Activity 6\n",
    "\n",
    "Draw a histogram of the $10,000$-step trajectory generated in the example of Activity #5 using the function `hist` from the module `matplotlib.pyplot`. Make sure that the histogram has one bin for each state. Compare the relative frequencies with the result of Activity #3.\n",
    "\n",
    "**Note**: Don't forget to load `matplotlib`. \n",
    "\n",
    "**Note 2**: Recall that the states in the trajectory from Activity #5 consist of strings, which should be converted to state indices to match the entries in the distribution computed in Activity #3.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-24T17:47:06.647350Z",
     "start_time": "2020-09-24T17:47:06.168651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stationary Distribution calculated in activity 3: [ 0.26315789  0.07894737  0.26315789  0.13157895  0.26315789]\n",
      "Observed relative frequencies: [0.26440000000000002, 0.075999999999999998, 0.26440000000000002, 0.1308, 0.26440000000000002]\n",
      "Is the stationary distribution close to the observed relative frequencies? True\n",
      "Do the observed relative frequencies sum up to 1? True\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7dec0202b0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add your code here.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nSteps = 10000\n",
    "chain = load_chain()\n",
    "nStates = len(chain[0])\n",
    "initialDist = np.ones((1, nStates)) / nStates\n",
    "\n",
    "traj = simulate(chain, initialDist, nSteps)\n",
    "distAct3 = stationary_dist(chain)\n",
    "\n",
    "trajs = []\n",
    "for i in traj:\n",
    "    trajs.append(int(i))\n",
    "    \n",
    "# Plotting histogram\n",
    "weights = np.ones_like(trajs) / nSteps\n",
    "\n",
    "plt.hist(trajs, weights=weights)\n",
    "plt.locator_params(axis='x', integer=True)\n",
    "plt.xlabel(\"Markov Chain States\")\n",
    "plt.ylabel(\"Relative Frequency\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "unique, counts = np.unique(traj, return_counts=True)\n",
    "absFrequencies = dict(zip(unique, counts))\n",
    "#relFrequencies = [absFrequencies[str(i)]/nSteps for i in range(nStates)]\n",
    "relFrequencies = []\n",
    "for i in range(nStates):\n",
    "    relFrequencies.append(absFrequencies[str(i)]/nSteps)\n",
    "    \n",
    "    \n",
    "# Compare Distributions\n",
    "print(\"Stationary Distribution calculated in activity 3: {}\".format(distAct3))\n",
    "print(\"Observed relative frequencies: {}\".format(relFrequencies))\n",
    "print('Is the stationary distribution close to the observed relative frequencies?', np.all(np.isclose(distAct3, relFrequencies,atol=0.01)))\n",
    "print(\"Do the observed relative frequencies sum up to 1? {}\".format(np.isclose(np.sum(relFrequencies),1,atol=0.001)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
